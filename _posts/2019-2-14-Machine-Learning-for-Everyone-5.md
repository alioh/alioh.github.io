---  
layout: post
title: تعلم الآلة للجميع - 5
---  

آخر أنواع طرق تعلم الآلة هو التعلم التعزيزي Reinforcement Learning،  فيه تتعلم الآلة بنفسها عن طريق التجارب، في حال قامت بعمل صحيح تكمل عليه وفي حال أخطأت تتوقف ولا تعيد نفس الخطأ.  
ذكرنا في [التدوينة الثانية](https://alioh.github.io/Machine-Learning-for-Everyone-2/) الأدوات الأساسية في التعليم التعزيزي وهي:
* **Agent الآلة** الآله التي نعمل على تدريبها.
* **Environment بيئة التعلم**: وهي المكان الذي تقوم فيه التجارب.
* **State الحالة**: الوضع الحالي للروبوت أو الآداة التي نُعَلمها.
* **Reward المكافئة (أو الرد بصح أو خطأ)**: وهي قرارات نحددها أثناء إنشاء قوانين المكافئات للآله، هذه القوانين تبين للآلة ما اذا كان فعلها صحيح أو خطأ، في كثير من الأحيان في حال كان الفعل من الآلة صحيح تعطى +1 أما إذا كان خاطئ تعطى 0 أو -1.
* **Action الفعل**: الحركة أو النشاط الذي قامت به الآلة.  
  
من الأمثله على إستخدام هذه الطريقة في التعلم هي الروبوتات، ألعاب الكمبيوتر والسيارات ذاتية القيادة. ما تختلف عنه هذه الطريقة عن [التعلم الموجَّه](https://alioh.github.io/Machine-Learning-for-Everyone-3/) و[التعلم الغير الموجَّه](https://alioh.github.io/Machine-Learning-for-Everyone-4/) هي أننا لا نحتاج لتقديم بيانات للآله.

##### كيف تتم عملية التعلم؟  
  
![](https://alioh.github.io/images/2019-2-14/1.png)  
لنقل مثلاً أننا نريد أن تتعلم الآلة كيفة لعب لعبة ألكترونية [^1]، طريقة تعلمها إتقان هذه اللعبه عن طريق عملية تكرار Loop وتعمل كالتالي:
* الآلة Agent تصل لها الحالة State الحالية من بيئة التعلم Environment.
* تُحَلل الآلة الحالة ثم تتخذ فعل / قرار Action، في الصورة العلوية القرار هو ضغط الزر اليمين.
* تنتقل الآلة إلى حالة جديدة وتحدد أن الفعل القرار السابق كان صحيحاً وتأخذ مكائفة Reward (+1).
* تخرج الآلة بنتيجة تذكر فيها الحالة + الفعل + المكافئة (State, Action, Reward)


من الخوارزميات المستخدمه في التعلم التعزيزي:


* **Q-learning خوارزمية التعلم Q**: [^2] [^3] [^4]
سأشرح الخوارزمية بمثال كي تتضح الصورة بشكل أفضل، لدينا آلة عبارة عن جندي ويريد الوصول إلى القلعه. أخبرنا الآلة أنها إذا فعلت شيء صحيح سنعطيها +1 وإذا أخطأت ( صادفت جنود أعداء مثلاً) سنعطيها -5، إذا وصلت للنهاية سنكافئها بـ+10.
![](https://alioh.github.io/images/2019-2-14/2.png)  
  
  * ننشئ جدول جديد تكون فيه الصفوف هي الحالات States (25 صف / حالة) والعواميد هي الأفعال Actions. في اللعبه الحالية توجد أربع أفعال إما الذهاب إلى اليمين، يسار، فوق أو تحت.

  ![](https://alioh.github.io/images/2019-2-14/3.png)  

  * تحدد الآلة الفعل التي تأخذه عن طريق معلومات سابقة لديها أن وجدت. وإن لم تجد تأخذ فعلاً عشوائياً.
  * بعد الفعل نستقبل المكافئة إما +1 وتعني أننا فعلاً خطوة صحيحة ولم نصطدم بعوائق، 
  * إذا كانت الخطوة صحيحة يتم تحديث صف الحالة بإضافة +1 لعامود الفعل الذي تم.
  * ننتقل للحالة التي تليها ونعيد نفس الخطوات مرة أخرى.
  * إذا صادفت الآلة عائق، تحدث الفعل بـ-1 وتأخذ فعل آخر.
  * تنتهي اللعبه عندما نصل لحالة تكافئنا فيه اللعبه ب+10 وتعني وصولنا للنهاية.
  
يمكن التغير في المكافئات إذا كنا نريد إيجاد أسرع الطرق لإنهاء اللعبه، أي يمكننا التحديد أن بعض الحالات مكافئتها متفاوته من 1 إلى 5 مثلاً، وفي نهاية اللعبه نطلب من اللعبه البدء من جديد والسير في المسارات الذي تحتوي على الرقم الأعلى من بين الأفعال في حالة معينة.


[^1]: <https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419>
[^2]: <https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe>
[^3]: <https://www.youtube.com/watch?v=aCEvtRtNO-M>
[^4]: <https://www.inf.ethz.ch/personal/cellier/MS/soto_ms.html>