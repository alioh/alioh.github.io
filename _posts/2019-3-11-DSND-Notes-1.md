---  
layout: post
title: ملخص كورس علم البيانات - 1
published: false
---  

هذه السلسلة من المنشورات ستكون ملخصات خاصه بي كتبتها أثناء دراستي لكورس [Udacity في علم البيانات](https://www.udacity.com/course/data-scientist-nanodegree--nd025) أحببت أفيد فيها المهتمين ومن يرغب بدخول مجال علم البيانات. قبل البداية يتوقع منك أن تكون لديك معرفة سابقة بلغة البرمجة بايثون وبعض مكاتبها المخصصه لعلم البيانات مثل scikit-learn.  


###### الفصل الأول  
##### الدرس الأول
### معلومات عامة عن تعلم الآلة

توجد ثلاث انواع من تعلم الآلة


##### التعلم الموجَّه Supervised Learning  
في التعليم الموجَّه، تتعلم الخوارزمية من البيانات التي لدينا ومن نتائجها، بعد أن تدرسها الخوارزمية، تستطيع توقع نتائج أي قيمة تقدم لها.  
![](https://alioh.github.io/images/2019-3-11/supervised.jpg)  
ينقسم التعليم الموجة إلى قسمين:
- Classification التصنيف: يستخدم لتوقع الفئة التي تنتمي لها البيانات. أو للنتائج التي لها خيارين. مثلاً ما إذا كانت رسالة البريد الإلكتروني مزعجة أو لا.  
- Regression الإنحدار: تستخدم لتوقع نتائج رقمية مثل أسعار المنازل.  
لمزيد من المعلومات عن التعلم الموجَّه سبق أن شرحته بشكل مفصل [هنا](https://alioh.github.io/Machine-Learning-for-Everyone-3/).  

##### التعلم غير الموجَّه Unsupervised Learning  
في التعليم الغير موجَّه، توجد لدينا بيانات بدون نتائج، فتحتاج الآلة للتعلم بنفسها، وتوجد أكثر من طريقة مثل تقسيم وتجميع البيانات حسب تشابهها.  
شرح أكثر تفصيل عن التعلم غير الموجَّه [هنا](https://alioh.github.io/Machine-Learning-for-Everyone-4/)  

#### التعلم التعزيزي Reinforcement Learning  
تتعلم الآلة هنا عن طريق عمل نشاطات أو Actions وتلقي نتائج من هذه النشاطات التي فعلتها.  
تم شرح التعلم التعزيزي بشكل مفصل في منشور سابق [هنا](https://alioh.github.io/Machine-Learning-for-Everyone-5/)  

------------

##### الدرس الثاني 
### الإنحدار الخطي Linear Regression
![](https://alioh.github.io/images/2019-3-11/house.png)  [^1]
في الصورة السابقة نريد الإجابة على سؤال، كم سيكون سعر البيت، بعد مقارنة النتائج وتحديد حجم البيت مقارنة ببقية البيوت، كم تتوقع يكون سعره؟
الإجابة 120 ألف، واجبنا عليه بواسطة رسم خط مناسب لكل النقاط (البيوت) التي لدينا في البيانات.

توجد طريقتين لرسم خط بين النقاط، الأولى هي عبر إستخدام Tricks او طرق لتحريك الخط، والثانية عن طريق إستخدام Error Functions وهي طريقة أخرى لموازنة الخط.

## الطريقة الأولى Tricks:
الهدف من رسم الخط هو ان يكون قريب جداً إلى النقاط ومناسب لهم جميعاً، بالتأكيد توجد طرق كثيره لرسم الخط في حال كانت لدينا نقاط كثيره وقد يناسب بعض النقاط ولكن لن يناسبها جميعها، الهدف هنا رسم خط يناسب الجميع.
ويوجد طريقتين لتحريك الخط [^2]:
![](https://alioh.github.io/images/2019-3-11/movingline.png)  

### A- Absolute Trick  
![](https://alioh.github.io/images/2019-3-11/movingline1.png)  
القيمة α هنا تعرف بالـ Learning rate. نقوم بتغيرة ليتغير مكان الخط.  
( If the point is below the line, the intercept decreases (subtract from w1 and w2); if the point has a negative x-value, the slope increases. )

### 2- Square Trick  
![](https://alioh.github.io/images/2019-3-11/movingline2.png)  
طريقة الحساب:  
نفرض لدينا النقطة: (x,y) = (-5, 3)  
والمعادله والتي تعني موقع الخط لدينا: y = -0.6x + 4  و α=0.01
في الصورة السابقة q تعني هنا y و q' نتيجة طرح q-q'.  
لإستخارج y للخط نقوم بتعويض x من النقطة في المعادلة y = -0.6x + 4  
y = -0.6 (-5)+4 = 7  
الآن q-q' = 3 - 7 = -4  
نعوض النتائج لنا في المعادلة  
y = (W1 + p (q - q')α) x + (W2 + (q - q')α)  
y = (-0.6+(-5 * -4 * 0.01))x + (4 + (-4 *0.01))
y = (-0.6+0.2)x + 3.96
y = -0.4x + 3.96


-----


### B- الطريقة الثانية Gradient Descent
طريقة لرسم الخط، في كل مرة تحسب المسافة بين الخط والنقاط، النتيجة من هذه الحسبه هي ما يسمى بالـError وهو مجموع كامل المسافات بين كل نقطة والخط.  
وهدف هذه الطريقة هي حسابه في كل مره والمحاولة ان تكون النتجية أقل ما يمكن.

طريقتين لحساب الـError:

### 1- Mean Absolute Error
مثال:  
لدينا هذا الخط y = 1.2x + 2  
واعطينا هذه النقاط:  
(2, -2), (5, 6), (-4, -4), (-7, 1), (8, 14)  
وطلب منا حساب Mean Absolute Error، المعادلة لحسابه هي مجموع المسافات بين النقاط والخط تقسيم عدد النقاط:  
اولاً نوجد المسافه بين كل نقطة والخط والطريقة هي اولاً إيجاد y' بواسطة حل y في معادلة الخط:  
مثال لأحد النقاط (-4, -4):  
y = 1.2x + 2  
y = 1.2*(-4) + 2  
y = -4.8 + 2  
y = -2.8  
ولحساب المسافه بين الـy الخط و y النقطة نقوم بالتالي:  
Error = -2.8 - -4 = 1.2  
ملاحظة: إذا كانت النتيجة بالسالب نأخذ القيمة المطلقة.  
النتيجة:  
(6.4 + 2 + 1.2 + 7.4 + 2.4) / 5 = 3.88  

### 2- Mean Squared Error
بنفس الطريقة السابقة، لكن هذه المرة ترسم مربعات من المسافه بين النقطة والخط، والعملية الحسابية تكون بحساب مساحة كل مربع وأخذ المتوسط.  
نأخذ النتيجة النهائية لمسافة النقاط من المثال السابق:  
(6.4, 2, 1.2, 7.4, 2.4) ونربع كل واحدة  
(40.96, 4, 1.44, 54.76, 5.76) بعد ذلك نضرب قسم المجموع على عدد النقاط:  
(40.96 + 4 + 1.44 + 54.76 + 5.76) / 5 = 106.92 / 5 = 21.38  


-----

في الأمثله السابقة 



[^1]: <https://medium.com/@elevenching/machine-learning-introduction-d2a91294667e>
[^2]: <https://towardsdatascience.com/supervised-learning-basics-of-linear-regression-1cbab48d0eba>