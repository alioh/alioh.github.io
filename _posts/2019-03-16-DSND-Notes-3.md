---  
layout: post
title: Ù…Ù„Ø®Øµ ÙƒÙˆØ±Ø³ Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - 3
icon: ğŸ“
---  

Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ø®Øµ Ø³ÙŠÙƒÙˆÙ† Ø¹Ù† Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø¨Ø§ÙŠØ² Ø§Ù„Ø¨Ø³ÙŠØ· Naive BayesØŒ ÙÙƒØ±ØªÙ‡Ø§ ÙˆØ¥Ø³ØªØ®Ø¯Ø§Ù…ØªÙ‡Ø§ØŒ Ø·Ø±ÙŠÙ‚Ø© Ø¥ÙØ³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ù…ÙƒØªØ¨Ø© scikit-learn ÙˆØ¨Ø¹Ø¶ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ù‡ ÙÙŠÙ‡Ø§ØŒ ÙˆØ·Ø±ÙŠÙ‚Ø© ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¯Ù„ ÙˆÙ†ØªØ§Ø¦Ø¬Ù‡.  

##### Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„ - Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…ÙˆØ¬Ù‘ÙÙ‡ Supervised Learning  
##### Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ø®Ø§Ù…Ø³ - Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø¨Ø§ÙŠØ² Ø§Ù„Ø¨Ø³ÙŠØ· Naive Bayes  
Ù…Ù† Ø§Ø´Ù‡Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§ØªÙ‡Ø§ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø§Ø°Ø§ ÙƒØ§Ù†Øª Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù…Ø²Ø¹Ø¬Ø© Ø£Ùˆ Ù„Ø§. Ø§Ø±ÙÙ‚Øª ÙÙŠ Ø§Ø³ÙÙ„ Ø§Ù„ØµÙØ­Ø© Ù…ØµØ§Ø¯Ø± Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³Ø§Ø¦Ù„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø®Ù„Ù Ù‡Ø°Ù‡ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©. [^1] [^2]
More info in jupyter notebook file.  

### Bag of words  
Ø§Ø³ØªØ®Ø¯Ù…Øª ÙÙŠ Ù…ÙˆØ¯Ù„ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø²Ø¹Ø¬Ø© Ø£Ùˆ Ù„Ø§. ÙˆÙ‡ÙŠ Ù†ÙØ³ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„ØªÙŠ Ø´Ø±Ø­Øª Ø³Ø§Ø¨Ù‚Ø§Ù‹ ÙÙŠ Decision Tree: One-hot encode.  
Ù‡Ù†Ø§ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© ØªÙƒÙˆÙ† Ø¨ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø¥Ù„Ù‰ Ø¹Ø§Ù…ÙˆØ¯. ÙˆÙÙŠ ÙƒÙ„ Ù…Ø±Ø© ØªØªÙƒØ±Ø± Ø§Ù„ÙƒÙ„Ù…Ø© ÙŠØ¶Ø§Ù 1 Ø¥Ù„Ù‰ Ø°Ù„Ùƒ Ø§Ù„Ø¹Ø§Ù…ÙˆØ¯ØŒ Ù…Ø«Ø§Ù„ Ù„Ø¯ÙŠÙ†Ø§ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ØªØ§Ù„ÙŠØ©:  
['Hello, how are you!',  
'Win money, win from home.',  
'Call me now',  
'Hello, Call you tomorrow?']  
Ø¨Ø¹Ø¯ ØªØ­ÙˆÙŠÙ„Ù‡Ø§ ØªØµØ¨Ø­ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:  
![](https://alioh.github.io/images/2019-3-16/countvectorizer.png)  

ØªØªÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø¯Ø§Ù„Ø© [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) ÙÙŠ scikit-learnØŒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù…Ø© ÙÙŠ Ø¹Ù…Ù„ Ø§Ù„Ø¯Ø§Ù„Ø©:  
- Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¥Ù„Ù‰ Lowercase Ø¥Ù„Ø§ Ø§Ø°Ø§ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ø´Ø±Ø·.
- Ø§Ù„Ø¯Ø§Ù„Ø© Ø£ÙŠØ¶Ø§Ù‹ ØªØ­Ø°Ù Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ù…Ø«Ù„ !.  
- Ø§Ù„Ù…ØªØºÙŠØ± stop_words ÙÙŠ Ø­Ø§Ù„ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ© Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙŠØ­Ø°Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø± Ù…Ø«Ù„ and, the, an ÙˆØºÙŠØ±Ù‡Ø§.  

Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„  
```python
from sklearn.feature_extraction.text import CountVectorizer

documents = ['Hello, how are you!',
                'Win money, win from home.',
                'Call me now.',
                'Hello, Call hello you tomorrow?']

#   create CountVectorizer instance and fit it to our list
count_vector = CountVectorizer()
count_vector.fit(documents)
#   transform it to array
doc_array = count_vector.transform(documents).toarray()
#   transform array to dataframe
frequency_matrix = pd.DataFrame(doc_array)
#   change column names to words
frequency_matrix.columns = count_vector.get_feature_names()
frequency_matrix
```
### Ø®Ø·ÙˆØ§Øª ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯Ù„  
- ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø®ØªØ¨Ø§Ø± ÙˆØ¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ train_test_split  
```python
X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], 
                                                    df['label'], 
                                                    random_state=1)
#   calculate the size of our dataframe
print('Number of rows in the total set: {}'.format(df.shape[0]))
print('Number of rows in the training set: {}'.format(X_train.shape[0]))
print('Number of rows in the test set: {}'.format(X_test.shape[0]))
```
Ø¨Ø¹Ø¯ ØªÙ‚Ø³ÙŠÙ…Ù‡Ø§ØŒ Ù†Ø­ÙˆÙ„Ù‡Ø§ Ù„Ù„Ø´ÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø¥Ø³ØªØ®Ø¯Ø§Ù… CountVectorizer:  
```python
count_vector = CountVectorizer()
training_data = count_vector.fit_transform(X_train)
testing_data = count_vector.transform(X_test).toarray()
```
Ø¨Ø¹Ø¯ ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµÙ†Ù (Classifier) MultinomialNB ÙƒÙˆÙ†Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØµÙ„Ø©. Ø¨ÙŠÙ†Ù…Ø§ Gaussian Naive Bayes Ù…Ù†Ø³Ø§Ø¨Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø©.  

```python
from sklearn.naive_bayes import MultinomialNB
naive_bayes = MultinomialNB()
naive_bayes.fit(training_data, y_train)

predictions = naive_bayes.predict(testing_data)
```

### ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¯Ù„  
- **Accuracy**: ÙŠØ­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Øª Ø§Ù„ØªÙŠ ÙƒØ§Ù†Øª Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…ÙØµÙ†Ù (Classifier) ØµØ­ÙŠØ­Ù‡.  
**Accuracy** measures how often the classifier makes the correct prediction. Itâ€™s the ratio of the number of correct predictions to the total number of predictions (the number of test data points).  
- **Precision**: ÙŠØ­Ø¯Ø¯ Ù†Ø³Ø¨Ø© Ù…Ø¯Ù‰ Ø¯Ù‚Ø© Ø§Ù„Ù…ÙØµÙ†Ù ÙÙŠ ØªÙˆÙ‚Ø¹Ø§ØªÙ‡ Ø§Ù„ØµØ­ÙŠØ­Ù‡.  
**Precision** tells us what proportion of messages we classified as spam, actually were spam.
It is a ratio of true positives(words classified as spam, and which are actually spam) to all positives(all words classified as spam, irrespective of whether that was the correct classification), in other words it is the ratio of  
`[True Positives/(True Positives + False Positives)]`  
- **Recall(sensitivity)**: ÙŠØ­Ø¯Ø¯ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ Ø­Ø¯Ø¯Ù†Ø§Ù‡Ø§ Ù†Ø­Ù† ÙƒÙ…Ø²Ø¹Ø¬Ù‡ (ÙÙŠ Ù…Ø«Ø§Ù„ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ)
**Recall(sensitivity)** tells us what proportion of messages that actually were spam were classified by us as spam.
It is a ratio of true positives(words classified as spam, and which are actually spam) to all the words that were actually spam, in other words it is the ratio of  
`[True Positives/(True Positives + False Negatives)]`  
- **F1 Score**: ÙˆØªØ¹Ù†ÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„ÙƒÙØ§Ø¦Ø© ÙˆØ¯Ù‚Ø© Ø§Ù„Ù…ÙˆØ¯Ù„. ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒØ§Ù„ØªØ§Ù„ÙŠ:  
`F1 Scode = 2 * ( (*Precision* * *Recall*) / (*Precision* + *Recall*) )`

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
print('Accuracy score: ', format(accuracy_score(y_test, predictions)))
print('Precision score: ', format(precision_score(y_test, predictions)))
print('Recall score: ', format(recall_score(y_test, predictions)))
print('F1 score: ', format(f1_score(y_test, predictions)))
```
  
  
-----
[Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ù…Ù„Ø®Øµ ÙƒÙˆØ±Ø³ Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - 2](https://alioh.github.io/DSND-Notes-2/)   -   [Ø§Ù„Ø¥Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ù„Ø®Øµ ÙƒÙˆØ±Ø³ Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - 4](https://alioh.github.io/DSND-Notes-4)  
  
  


[^1]: [AnalyticsVidhya](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/)
[^2]: [SaedSayad](https://www.saedsayad.com/naive_bayesian.htm)
